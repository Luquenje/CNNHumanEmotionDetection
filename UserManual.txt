Setup:
The project contains a conda_python_env.yaml file. This file contains the python environment nessecary to run the python files in this project. 
1. Install Anaconda and make sure it is added to your system's path environment variable.
2. Open Anaconda. Go to environments and import the conda_python_env.yaml as a new python virtual environment.
3. Run the python files in the project in the imported python virtual environment. 
4. To run the python files from the command line, type conda activate <environment_name> to switch the python environment to the newly imported one.
5. Type python <filename.py args> to run the python code (The args are for files that require arguments)

Project
This project contains 6 python files.

TrainEmotionDetectorVGG16.py
This program trains a vgg16 convolutional neural network model on the FER-2013 dataset to detect 7 human emotions. 
It outputs 2 files.
VGG16_model.json - Contains the model information
VGG16_model.h5 - Contains the trained weights of the model

TrainEmotionDetectorResNet50.py
This program trains a ResNet50 convolutional neural network model on the FER-2013 dataset to detect 7 human emotions. 
It outputs 2 files.
ResNet50_model.json - Contains the model information
ResNet50_model.h5 - Contains the trained weights of the model

EvaluateEmotionDetectorVGG16.py & EvaluateEmotionDetectorResNet50.py
This program evaluates the trained model on the test image set of the FER-2013 dataset.
The evaluation gives information such as accuracy, precision, recall, f1-score and a confusion matrix

TestEmotionDetectorVGG16.py & TestEmotionDetectorResNet50.py
This program loads the trained model and tests it on sample videos.
It uses the cv2 library's haarcascade frontal face detection to detect faces.
The detected faces are resized so that it can be run through the model and the output emotion detected will be displayed on the video.
By default the program loads one of the sample videos.
This program supports using webcam if you want to try it on your own face!
The command line arguments are
Run with webcam:
python TestEmotionDetectorVGG16.py Webcam
python TestEmotionDetectorResNet50.py Webcam
Run with a specific video:
python TestEmotionDetectorVGG16.py <filepath>
python TestEmotionDetectorResNet50.py <filepath>

